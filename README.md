# ğŸŒ¤ï¸ dbt-weather-poc

Pipeline analytique MÃ©tÃ©o-France â€” ingestion, historisation et modÃ©lisation de donnÃ©es horaires â€” basÃ© sur **dbt** et **DuckDB** (avec **Python** pour lâ€™ingestion, **Streamlit** pour lâ€™exposition BI et **Prefect** pour lâ€™orchestration locale).

Objectif : **dÃ©montrer, de bout en bout, la maÃ®trise dâ€™un workflow moderne dbt**, depuis la collecte des donnÃ©es jusquâ€™Ã  leur exposition en BI (dashboard) et leur orchestration.

Pourquoi cela compte pour unÂ·e clientÂ·e ou recruteurÂ·e :
- donnÃ©es rÃ©elles (API MÃ©tÃ©o-France) avec ingestion maÃ®trisÃ©e,
- bonnes pratiques dbt (layering, tests, contrats, macros, incrÃ©mental),
- exposition BI concrÃ¨te (Streamlit + exposure dÃ©clarÃ©e),
- orchestration lÃ©gÃ¨re (Prefect) + CI double : build dbt sur donnÃ©es fraÃ®ches et gÃ©nÃ©ration/dÃ©ploiement automatique de la doc.

---

## Ce que ce projet met en Å“uvre cÃ´tÃ© dbt

Ce repository illustre concrÃ¨tement :

* **Sources dÃ©clarÃ©es** avec contrÃ´le de fraÃ®cheur (`loaded_at_field`)
* **Tests dbt** : not_null, unique, relationships, contraintes mÃ©tier, tests gÃ©nÃ©riques
* **Contrats de schÃ©ma** sur les modÃ¨les critiques
* **Organisation modulaire** : `staging â†’ intermediate â†’ marts`
* **ModÃ¨les incrÃ©mentaux** (stratÃ©gie `merge`)
* **Macros personnalisÃ©es** (features mÃ©tÃ©o, conversions, casts, time series analysis)
* **Seeds** (Ã©chelle de Beaufort)
* **Exposures** (dashboard Streamlit comme consommateur final)
* **Documentation dbt** (descriptions, docs blocks, lineage graph)
* **Facteurs mÃ©tier** : dimensions stations & vent, table de faits horaire
* **Publication automatique de la documentation dbt** (GitHub Actions + GitHub Pages)
* **Orchestration locale** du pipeline ingestion + dbt avec **Prefect** (flow, deployment, schedule horaire)

Lâ€™objectif nâ€™est pas la BI en tant que produit, mais **la dÃ©monstration des bonnes pratiques dbt** dans un pipeline rÃ©aliste.

---

## Architecture globale

```text
MÃ©tÃ©o-France API
    â†“
Ingestion Python
    â†“
DuckDB (raw.*)
    â†“
dbt (staging â†’ intermediate â†’ marts)
    â†“
Dashboard Streamlit (exposure)
```

ğŸ‘‰ Pour plus de dÃ©tails sur chaque brique, voir la documentation complÃ©mentaire ci-dessous.

---

## ğŸ“ Documentation complÃ©mentaire

La documentation dÃ©taillÃ©e du projet est organisÃ©e par brique :

- [`docs/ingestion.md`](docs/ingestion.md) â€” ingestion API MÃ©tÃ©o-France â†’ DuckDB (`raw.*`)
- [`docs/warehouse.md`](docs/warehouse.md) â€” commandes pour explorer le warehouse DuckDB
- [`docs/dbt.md`](docs/dbt.md) â€” structure des modÃ¨les dbt, layering et incrÃ©mental
- [`docs/dbt-docs.md`](docs/dbt-docs.md) â€” gÃ©nÃ©ration et exploration de dbt Docs (lineage, tests, modÃ¨les)
- [`docs/dashboard.md`](docs/dashboard.md) â€” dashboard Streamlit (exposure dbt)
- [`docs/orchestration.md`](docs/orchestration.md) â€” orchestration locale du pipeline avec Prefect


---

## Stack technique

- **Python 3.12** â€” ingestion & utilitaires
- **DuckDB (CLI + lib Python)** â€” data warehouse local
- **dbt-core + dbt-duckdb** â€” transformation & tests
- **Streamlit** â€” exposition BI
- **SQLFluff / Ruff** â€” linting SQL & Python
- **GitHub Actions** â€” gÃ©nÃ©ration et dÃ©ploiement automatique des docs dbt (CI) + build dbt avec ingestion API
- **Prefect 3** â€” orchestration locale *lÃ©gÃ¨re* (flow + deployment horaire)

---

## ğŸš€ Mise en route

### (Option Docker) ExÃ©cuter sans installer l'environnement Python

PrÃ©-requis : Docker + Docker Compose, un fichier `.env` (copie de `.env.example`).

Raccourcis fournis dans `scripts/docker/` :

```bash
./scripts/docker/docker-ingest.sh   # ingestion
./scripts/docker/docker-dbt.sh      # dbt build
./scripts/docker/docker-app.sh      # Streamlit (port 8501)
```

Volume montÃ© : `./data` (warehouse) est partagÃ© avec le conteneur.

#### DÃ©velopper/tester depuis le conteneur

- Shell interactif avec le code de l'hÃ´te montÃ© (hot-reload Streamlit, pas besoin de rebuild pour le code) :
  ```bash
  docker compose run --rm -v "$(pwd)":/app weather-app sh
  ```
  Depuis le shell : `make dwh-ingest`, `make dbt-build`, ou `streamlit run apps/bi-streamlit/app.py`.
- Si vous modifiez `requirements.txt`, rebuilder l'image : `docker compose build`.
- Avec Docker Compose v2 : `docker compose watch` synchronise le code (hot-reload) et ne rebuild que si `requirements.txt` ou `Dockerfile` changent (voir `compose.yaml` bloc `develop.watch`).

---

### 1. Installer lâ€™environnement

```bash
make env-setup
source .venv/bin/activate
```

### 2. Variables dâ€™environnement

CrÃ©er un fichier `.env` :

```bash
METEOFRANCE_TOKEN=xxxxxxxxxxxx
DUCKDB_PATH=data/warehouse.duckdb
```
avec `METEOFRANCE_TOKEN` la clÃ© API MÃ©tÃ©o-France et `DUCKDB_PATH` le chemin du fichier DuckDB.

### 3. Activer le profil dbt

```bash
export DBT_PROFILES_DIR=./profiles
```

### 4. Ingestion brute (API â†’ DuckDB)

```bash
make dwh-ingest DEPT=9
```

RÃ©sultat attendu :
- donnÃ©es brutes dans `raw.obs_hourly` et `raw.stations`
- pas de transformation / typage
- dÃ©duplication automatique

ğŸ‘‰ Documentation dÃ©taillÃ©e : [`docs/ingestion.md`](docs/ingestion.md).

### 5. ModÃ©lisation dbt

```bash
make dbt-build
```

---

## ğŸ§© ModÃ©lisation dbt (vue dÃ©taillÃ©e)

Points clÃ©s du projet dbt :

* **Layering clair** :

  * `staging` = nettoyage + typage,
  * `intermediate` = calculs mÃ©tier (features mÃ©tÃ©o, agrÃ©gations),
  * `marts` = tables de faits et dimensions analytiques.
* **QualitÃ©** :

  * tests gÃ©nÃ©riques (intÃ©gritÃ©, clÃ©s, relations),
  * tests mÃ©tier (plages de valeurs, non-nÃ©gativitÃ©, etc.),
  * contrats de schÃ©ma sur les modÃ¨les exposÃ©s.
* **Performance & maintenabilitÃ©** :

  * modÃ¨les incrÃ©mentaux pour limiter les coÃ»ts de recalcul,
  * macros pour mutualiser les conversions, features mÃ©tÃ©o et logiques temporelles.

ğŸ‘‰ Documentation dÃ©taillÃ©e : [`docs/dbt.md`](docs/dbt.md).

---

## ğŸ“š Documentation dbt

### Local

```bash
make dbt-docs-generate
make dbt-docs-serve
```

AccÃ¨s : [http://localhost:8080](http://localhost:8080)

### HÃ©bergÃ©e (CI â†’ GitHub Pages)

Une GitHub Action gÃ©nÃ¨re et dÃ©ploie automatiquement la documentation dbt Ã  chaque push sur `main` (build + upload artefact, puis publication sur Pages) :

- AccÃ¨s : [https://martinezcoralie.github.io/dbt-weather-poc/](https://martinezcoralie.github.io/dbt-weather-poc/)

ğŸ‘‰ Documentation dÃ©taillÃ©e : [`docs/dbt-docs.md`](docs/dbt-docs.md).

---

## ğŸ“Š Dashboard Streamlit (exposure dbt)

Lancer le dashboard :

```bash
streamlit run apps/bi-streamlit/app.py
```

AccÃ¨s : [http://localhost:8501](http://localhost:8501)

Le dashboard consomme les marts dbt stockÃ©s dans DuckDB (dimensions de stations, Ã©chelle de Beaufort, faits horaires).

ğŸ‘‰ DÃ©tails : [`docs/dashboard.md`](docs/dashboard.md).

---


## âœ… CI dbt (build + API MÃ©tÃ©o-France)

Une CI GitHub Actions rejoue une partie du pipeline Ã  chaque push / PR sur `main` :

- ingestion des donnÃ©es brutes depuis lâ€™API MÃ©tÃ©o-France via `make dwh-ingest DEPT=9`,
- crÃ©ation dâ€™un warehouse DuckDB local dans lâ€™environnement CI,
- exÃ©cution de `dbt deps` puis `dbt build` avec `DBT_PROFILES_DIR=./profiles`.

La CI sâ€™appuie sur :

- un secret GitHub Actions `METEOFRANCE_TOKEN` (clÃ© API MÃ©tÃ©o-France),
- une variable dâ€™environnement `DUCKDB_PATH` pointant vers `data/warehouse.duckdb`.

Ce choix permet de tester les modÃ¨les dbt et leurs tests mÃ©tier sur des donnÃ©es rÃ©elles, sans versionner les donnÃ©es MÃ©tÃ©o-France dans le dÃ©pÃ´t.

---


## âš™ï¸ Orchestration locale (Prefect â€” bonus)

Une orchestration locale est mise en place avec **Prefect 3** :

* un flow `weather_hourly_pipeline` orchestre :

  * lâ€™ingestion (API â†’ DuckDB),
  * puis `dbt build`,
* un deployment Prefect avec schedule horaire pilote lâ€™exÃ©cution rÃ©guliÃ¨re du pipeline tant que le serveur Prefect et le process de service tournent.

Cette orchestration est volontairement lÃ©gÃ¨re : elle sert Ã  montrer comment **plugger un orchestrateur moderne autour dâ€™un projet dbt existant**, sans complexifier le cÅ“ur du repo.

ğŸ‘‰ DÃ©tails : [`docs/orchestration.md`](docs/orchestration.md).

---

## ğŸ§° Commandes (Makefile)

Toutes les commandes (ingestion, dbt, docs, utilitaires DuckDB, lint, etc.) sont centralisÃ©es dans le **Makefile** :

```bash
make help
```

---

## Scope & limites

Ce projet :

* est centrÃ© sur la **dÃ©monstration de bonnes pratiques dbt** (structure, tests, contrats, docs, exposures),
* embarque une CI et une orchestration locale pour illustrer lâ€™intÃ©gration de dbt dans un pipeline complet,
* **ne vise pas** (dans cette version) :

  * un dÃ©ploiement 24/7 sur une infra cloud,
  * une BI mÃ©tier aboutie.

---

## Prochaines Ã©volutions

* Ã‰tendre la CI/CD (artefacts, checks supplÃ©mentaires, Ã©ventuels dÃ©ploiements),
* DÃ©ployer pipeline + dashboard sur une infra cloud (VM / containers),
* Approfondir lâ€™orchestration (Prefect Cloud / autre orchestrateur) si besoin projet.

---

## ğŸ‘¤ Auteur

Coralie Martinez
