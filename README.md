# dbt-weather-poc

Pipeline d‚Äôingestion et de mod√©lisation M√©t√©o-France (Paquet Observations DPPaquetObs)  
Bas√© sur **DuckDB**, **Python**, et **dbt**.

> Ce projet DBT collecte et historise les observations m√©t√©o horaires de M√©t√©o France pour le d√©partement de l‚ÄôAri√®ge afin d‚Äôanalyser la qualit√© de vie climatique selon les zones (soleil, humidit√©, vent, pluie).

Les marts sont expos√©s dans un petit dashboard Streamlit (cf. section üìä Visualisation BI).

## üí° Objectifs

- D√©montrer un flux de donn√©es complet **API ‚Üí Warehouse ‚Üí dbt**, portable et reproductible.
- Illustrer la cha√Æne de valeur **ingestion ‚Üí mod√©lisation ‚Üí documentation**.
- Montrer l‚Äôusage de mod√®les **incr√©mentaux dbt** pour optimiser les mises √† jour de donn√©es horaires.

### Architecture

```
M√©t√©o-France API
    ‚Üì
Ingestion Python
    ‚Üì
DuckDB (raw.*)
    ‚Üì
dbt models
    ‚Üì
Analyses / Visualisations
```
---

## üõ†Ô∏è Mise en place

### Installer l'environnement
```bash
make env-setup
```

### Activer l'environnement
```bash
source .venv/bin/activate
```

### D√©finir les variables d‚Äôenvironnement
Cr√©er un fichier `.env` :
```bash
METEOFRANCE_TOKEN=xxxxxxxxxxxxxxxx
DUCKDB_PATH=data/warehouse.duckdb
```
avec :
- `METEOFRANCE_TOKEN` : la cl√© API M√©t√©o-France  
- `DUCKDB_PATH` : le chemin du fichier DuckDB (par d√©faut `data/warehouse.duckdb`)


### Activer le profil local
```bash
export DBT_PROFILES_DIR=./profiles
```

---

## üîß Ingestion des donn√©es (API ‚Üí DuckDB)

### Lancer une ingestion d√©partementale
```bash
make dwh-ingest DEPT=75
```
**Ce que fait la commande :**

* cr√©e `warehouse.duckdb` si absent ;
* interroge l‚ÄôAPI M√©t√©o-France (derni√®res **24 h**) pour le d√©partement `DEPT` ;
* √©crit en **brut** dans `raw.stations` et `raw.obs_hourly`.

**Garantie de ‚Äúraw‚Äù :**

* ‚úÖ Noms de colonnes **strictement identiques** √† la source (aucun renommage, aucun `lower/strip`)
* ‚úÖ Types **inchang√©s** (strings le cas √©ch√©ant)
* ‚úÖ Aucune normalisation d‚Äôunit√©s / s√©mantique (fait plus tard en **staging dbt**)
* ‚ûï Champs ajout√©s par l‚Äôingestion : `load_time` (UTC) et `dept_code`

**Idempotence & d√©duplication :**

* Les doublons sont emp√™ch√©s via la cl√© logique
  `(validity_time, geo_id_insee, reference_time)` : seules les lignes nouvelles sont ajout√©es.

**Param√®tres requis :**

* `METEOFRANCE_TOKEN` (cl√© API)
* `DUCKDB_PATH` (par d√©faut `data/warehouse.duckdb`)

---

### Mesurer la fra√Æcheur des sources (dbt)

```bash
make dbt-sources-freshness
```

**Comment √ßa marche :**

* dbt lit `loaded_at_field: load_time` (d√©fini dans `sources.yml`)
* compare `load_time` √† l‚Äôhorloge actuelle, et applique les seuils :

  * ‚ö†Ô∏è **warn** si `load_time` > **2 h**
  * ‚õî **error** si `load_time` > **4 h**

**Lecture des r√©sultats :**

* ‚úÖ **pass** : la source est √† jour
* ‚ö†Ô∏è **warn** : donn√©es en retard (surveillance conseill√©e)
* ‚õî **error** : pipeline consid√©r√© **en √©chec**

**Que faire en cas d‚Äôalerte/erreur ?**

1. Relancer l‚Äôingestion :

   ```bash
   make dwh-ingest DEPT=09
   ```
2. V√©rifier le token API et la connectivit√© r√©seau.

---

### Ex√©cuter les tests de sch√©ma et de donn√©es (dbt)

```bash
make dbt-sources-test
```
Les tests effectu√©es sont ceux d√©clar√©s dans `sources.yml`.

---

## üîé Inspection du DataWarehouse (DuckDB)

### Lister l'ensemble des tables
```bash
make dwh-tables
```
Cela permet de visualiser les schemas et noms de toutes les tables du DataWarehouse.

### Afficher les colonnes d'une table
```bash
make dwh-table-info TABLE=raw.stations
```
Cela permet de visualiser les noms des colonnes de la table `TABLE` et leur type.

### Afficher un extrait d'une table
```bash
make dwh-table-sample TABLE=raw.stations
```
Permet de visualiser un extrait des donn√©es de la table `TABLE` directement dans le terminal.

### Afficher les dimensions d'une table
```bash
make dwh-table-shape TABLE=raw.stations
```
Permet de visualiser le nombre de lignes et de colonnes de la table `TABLE`.

### Afficher toute les infos d'une table
```bash
make dwh-table TABLE=raw.stations
```
Permet de visualiser colonnes + dimensions + extrait de la table `TABLE`.

### Explorer le warehouse avec DuckDB CLI

#### Installation du client DuckDB
```bash
brew install duckdb
```

#### Ouvrir le shell interactif
```bash
duckdb warehouse.duckdb
```

#### Commandes utiles
```sql
show;                                  -- liste les tables
select count(*) from raw.stations;     -- compte les lignes d'une table
select * from raw.obs_hourly limit 5;  -- aper√ßu des donn√©es
show raw.stations;                     -- affiche le sch√©ma d'une table
```

---

## ‚öôÔ∏è dbt ‚Äî ex√©cution par actions

### 1) Tester la connexion au DWH
```bash
dbt debug
```

### 2) Lancer l‚Äôex√©cution de tous les mod√®les
```bash
make dbt-build     # deps + run
```

### 2.bis) Ex√©cuter un sous-ensemble de mod√®les

```bash
dbt run --select stg_obs_hourly      # un mod√®le
dbt run --select tag:stg     # tous les mod√®les ayant le tag `stg`
dbt run --full-refresh -s tag:int # full refresh cibl√©
```

### 3) Lancer les tests

```bash
make dbt-test    # tous les tests
dbt test -s tag:staging  # cibler un tag
```

### 4) Lancer un rebuild complet

```bash
make dbt-rebuild    # reset + deps + run --full-refresh + test
```

### √Ä propos des mod√®les incr√©mentaux

Ce projet utilise des mod√®les **incr√©mentaux dbt** pour √©viter de recalculer l‚Äôhistorique complet √† chaque ex√©cution.

Concr√®tement :

* seules les nouvelles observations m√©t√©o sont trait√©es ;
* l‚Äôhistorique d√©j√† calcul√© est conserv√© ;
* l‚Äôex√©cution est plus rapide et plus √©conomique qu‚Äôun *full refresh*.

Les mod√®les concern√©s :

* `intermediate.int_obs_features`
* `intermediate.int_obs_windowing`

Ces mod√®les sont bas√©s sur la cl√© `event_id` et utilisent la strat√©gie `merge`.

Pour forcer un recalcul complet :

```bash
make dbt-rebuild
```

---

## üìö Documentation dbt (catalogue + lineage)

Une fois les mod√®les ex√©cut√©s (`make dbt-rebuild`), on peut g√©n√©rer et explorer la
documentation dbt (mod√®les, sources, tests, lineage).

### G√©n√©rer la documentation

```bash
make dbt-docs-generate
```

Cela cr√©e les fichiers HTML/JSON de documentation dans le dossier `target/`.

### Servir la documentation en local

```bash
make dbt-docs-serve
```

Puis ouvrir le navigateur sur :

* [http://localhost:8080](http://localhost:8080)

On y retrouve :

* la liste des sources et mod√®les (staging, intermediate, marts) ;
* les descriptions de tables et de colonnes d√©finies dans les fichiers YAML ;
* les tests associ√©s ;
* le **graph de lineage** permettant de visualiser le flux `raw ‚Üí staging ‚Üí intermediate ‚Üí marts`. Accessible via le bouton ¬´ Lineage ¬ª en bas √† droite du panneau dbt Docs : <img src="docs/images/lineage-graph-icon.png" width="50">


---

## üìä Visualisation BI (dashboard Streamlit)

Une fois les donn√©es ing√©r√©es et les mod√®les dbt ex√©cut√©s, on peut explorer les marts via une petite app Streamlit.

### Lancer le dashboard

```bash
# 1) S'assurer que l'environnement est pr√™t
make env-setup
source .venv/bin/activate

# 2) Lancer l'application Streamlit
streamlit run apps/bi-streamlit/app.py
```

Par d√©faut, le dashboard est disponible sur :

* [http://localhost:8501](http://localhost:8501)

Le dashboard lit directement dans le fichier DuckDB (`DUCKDB_PATH`, par d√©faut `data/warehouse.duckdb`)
et s‚Äôappuie sur les mod√®les marts, notamment :

* `marts.meteofrance.fct_obs_hourly`
* `marts.meteofrance.dim_stations`
* `marts.meteofrance.agg_daily_station`

### Models en amont du dashboard (exposure dbt)

Ce projet d√©finit un **exposure dbt** nomm√© `weather_bi_streamlit`, qui repr√©sente le dashboard Streamlit comme un consommateur final des donn√©es.

Cet exposure permet d‚Äô**identifier explicitement** quels mod√®les dbt alimentent le dashboard, et donc de **s√©lectionner, tester ou ex√©cuter uniquement le p√©rim√®tre r√©ellement utilis√©** par la BI.

```bash
# Voir les mod√®les qui alimentent le dashboard
dbt ls -s +exposure:weather_bi_streamlit

# Ex√©cuter uniquement ces mod√®les
dbt run -s +exposure:weather_bi_streamlit
dbt test -s +exposure:weather_bi_streamlit
```

üí° **Int√©r√™t**
Si, plus tard, le projet comporte d‚Äôautres mod√®les non utilis√©s par le dashboard
(ex. nouveaux marts, analyses, features), ces commandes permettent de :

* ne construire **que** ce qui alimente le dashboard ;
* r√©duire le temps d‚Äôex√©cution ;
* √©viter de tester ou builder des mod√®les hors scope BI.

---

### üìä Prochaines √©tapes

* Configurer CI (`dbt build`, tests, docs)
* Publier artefacts (docs/lineage)
* Enrichir l‚Äôexposition `weather_bi_streamlit` au fil des √©volutions du projet

---

## Annexes

### üß∞ Scripts ingestion

#### `scripts/ingestion/fetch_meteofrance_paquetobs.py`

Client fetch-only :
- Appels API `/liste-stations` et `/paquet/horaire`
- Parsing CSV **sans aucune transformation**
- Retourne des DataFrames RAW

#### `scripts/ingestion/write_duckdb_raw.py`

Writer vers DuckDB :
- cr√©ation du sch√©ma `raw`
- `load_time` et `dept_code` ajout√©s
- d√©duplication sur PK logique

---

**Auteur :** Coralie Martinez
