# üå§Ô∏è dbt-weather-poc

Pipeline analytique M√©t√©o-France ‚Äî ingestion, historisation et mod√©lisation de donn√©es horaires ‚Äî bas√© sur **dbt** et **DuckDB** (avec **Python** pour l‚Äôingestion, **Streamlit** pour l‚Äôexposition BI et **Prefect** pour l‚Äôorchestration locale).

Objectif : **d√©montrer, de bout en bout, la ma√Ætrise d‚Äôun workflow moderne dbt**, depuis la collecte des donn√©es jusqu‚Äô√† leur exposition en BI (dashboard) et leur orchestration.

Pourquoi cela compte pour un¬∑e client¬∑e ou recruteur¬∑e :
- donn√©es r√©elles (API M√©t√©o-France) avec ingestion ma√Ætris√©e,
- bonnes pratiques dbt (layering, tests, contrats, macros, incr√©mental),
- exposition BI concr√®te (Streamlit + exposure d√©clar√©e),
- orchestration l√©g√®re (Prefect) + CI double : build dbt sur donn√©es fra√Æches et g√©n√©ration/d√©ploiement automatique de la doc.

---

## Ce que ce projet met en ≈ìuvre c√¥t√© dbt

Ce repository illustre concr√®tement :

* **Sources d√©clar√©es** avec contr√¥le de fra√Æcheur (`loaded_at_field`)
* **Tests dbt** : not_null, unique, relationships, contraintes m√©tier, tests g√©n√©riques
* **Contrats de sch√©ma** sur les mod√®les critiques
* **Organisation modulaire** : `staging ‚Üí intermediate ‚Üí marts`
* **Mod√®les incr√©mentaux** (strat√©gie `merge`)
* **Macros personnalis√©es** (features m√©t√©o, conversions, casts, time series analysis)
* **Seeds** (√©chelle de Beaufort)
* **Exposures** (dashboard Streamlit comme consommateur final)
* **Documentation dbt** (descriptions, docs blocks, lineage graph)
* **Facteurs m√©tier** : dimensions stations & vent, table de faits horaire
* **Publication automatique de la documentation dbt** (GitHub Actions + GitHub Pages)
* **Orchestration locale** du pipeline ingestion + dbt avec **Prefect** (flow, deployment, schedule horaire)

L‚Äôobjectif n‚Äôest pas la BI en tant que produit, mais **la d√©monstration des bonnes pratiques dbt** dans un pipeline r√©aliste.

---

## Architecture globale

```text
M√©t√©o-France API
    ‚Üì
Ingestion Python
    ‚Üì
DuckDB (raw.*)
    ‚Üì
dbt (staging ‚Üí intermediate ‚Üí marts)
    ‚Üì
Dashboard Streamlit (exposure)
```

üëâ Pour plus de d√©tails sur chaque brique, voir la documentation compl√©mentaire ci-dessous.

---

## üìé Documentation compl√©mentaire

La documentation d√©taill√©e du projet est organis√©e par brique :

- [`docs/ingestion.md`](docs/ingestion.md) ‚Äî ingestion API M√©t√©o-France ‚Üí DuckDB (`raw.*`)
- [`docs/warehouse.md`](docs/warehouse.md) ‚Äî commandes pour explorer le warehouse DuckDB
- [`docs/dbt.md`](docs/dbt.md) ‚Äî structure des mod√®les dbt, layering et incr√©mental
- [`docs/dbt-docs.md`](docs/dbt-docs.md) ‚Äî g√©n√©ration et exploration de dbt Docs (lineage, tests, mod√®les)
- [`docs/dashboard.md`](docs/dashboard.md) ‚Äî dashboard Streamlit (exposure dbt)
- [`docs/orchestration.md`](docs/orchestration.md) ‚Äî orchestration locale du pipeline avec Prefect


---

## Stack technique

- **Python 3.12** ‚Äî ingestion & utilitaires
- **DuckDB (CLI + lib Python)** ‚Äî data warehouse local
- **dbt-core + dbt-duckdb** ‚Äî transformation & tests
- **Streamlit** ‚Äî exposition BI
- **SQLFluff / Ruff** ‚Äî linting SQL & Python
- **GitHub Actions** ‚Äî g√©n√©ration et d√©ploiement automatique des docs dbt (CI) + build dbt avec ingestion API
- **Prefect 3** ‚Äî orchestration locale *l√©g√®re* (flow + deployment horaire)

---

## üöÄ Mise en route

### (Option Docker) Ex√©cuter sans installer l'environnement Python

Pr√©-requis : Docker + Docker Compose, un fichier `.env` (copie de `.env.example`).

Deux parcours possibles :

**1) Parcours complet (ingestion + dbt + app) ‚Äî requiert la cl√© API M√©t√©oFrance**
- Pr√©parer `.env` avec `METEOFRANCE_TOKEN` et `DUCKDB_PATH=data/warehouse.duckdb`
- Commandes :
  ```bash
  ./scripts/docker/docker-ingest.sh   # ingestion (API M√©t√©o-France)
  ./scripts/docker/docker-dbt.sh      # dbt build
  ./scripts/docker/docker-app.sh      # Streamlit (port 8501)
  ```
- Volume par d√©faut : volume nomm√© `weather-data:/app/data` (seed√© au 1er run, persistant ensuite).

**2) Parcours d√©mo (dbt + app) ‚Äî DuckDB embarqu√©**
- L‚Äôimage contient un DuckDB de d√©mo sous `/app/data/warehouse.duckdb`
- Volume nomm√© `weather-data:/app/data` : au premier run, le DuckDB d√©mo est copi√© dans le volume, puis r√©utilis√© entre les runs.
- Commandes :
  ```bash
  ./scripts/docker/docker-dbt.sh      # dbt build (sur le warehouse d√©mo)
  ./scripts/docker/docker-app.sh      # Streamlit
  ```

Volume par d√©faut : volume nomm√© `weather-data` mont√© sur `/app/data`.
Pour repartir de la d√©mo (reset warehouse) : `docker compose down -v` pour supprimer le volume nomm√©, puis relancer les scripts.

#### D√©velopper/tester depuis le conteneur
- Si vous modifiez `requirements.txt`, rebuilder l'image : `docker compose build`.
- Avec Docker Compose v2 : `docker compose watch` synchronise le code (hot-reload) et ne rebuild que si `requirements.txt` ou `Dockerfile` changent (voir `compose.yaml` bloc `develop.watch`).

---

### 1. Installer l‚Äôenvironnement

```bash
make env-setup
source .venv/bin/activate
```

### 2. Variables d‚Äôenvironnement

Cr√©er un fichier `.env` :

```bash
METEOFRANCE_TOKEN=xxxxxxxxxxxx
DUCKDB_PATH=data/warehouse.duckdb
```
avec `METEOFRANCE_TOKEN` la cl√© API M√©t√©o-France et `DUCKDB_PATH` le chemin du fichier DuckDB.

### 3. Activer le profil dbt

```bash
export DBT_PROFILES_DIR=./profiles
```

### 4. Ingestion brute (API ‚Üí DuckDB)

```bash
make dwh-ingest DEPT=9
```

R√©sultat attendu :
- donn√©es brutes dans `raw.obs_hourly` et `raw.stations`
- pas de transformation / typage
- d√©duplication automatique

üëâ Documentation d√©taill√©e : [`docs/ingestion.md`](docs/ingestion.md).

### 5. Mod√©lisation dbt

```bash
make dbt-build
```

---

## üß© Mod√©lisation dbt (vue d√©taill√©e)

Points cl√©s du projet dbt :

* **Layering clair** :

  * `staging` = nettoyage + typage,
  * `intermediate` = calculs m√©tier (features m√©t√©o, agr√©gations),
  * `marts` = tables de faits et dimensions analytiques.
* **Qualit√©** :

  * tests g√©n√©riques (int√©grit√©, cl√©s, relations),
  * tests m√©tier (plages de valeurs, non-n√©gativit√©, etc.),
  * contrats de sch√©ma sur les mod√®les expos√©s.
* **Performance & maintenabilit√©** :

  * mod√®les incr√©mentaux pour limiter les co√ªts de recalcul,
  * macros pour mutualiser les conversions, features m√©t√©o et logiques temporelles.

üëâ Documentation d√©taill√©e : [`docs/dbt.md`](docs/dbt.md).

---

## üìö Documentation dbt

### Local

```bash
make dbt-docs-generate
make dbt-docs-serve
```

Acc√®s : [http://localhost:8080](http://localhost:8080)

### H√©berg√©e (CI ‚Üí GitHub Pages)

Une GitHub Action g√©n√®re et d√©ploie automatiquement la documentation dbt √† chaque push sur `main` (build + upload artefact, puis publication sur Pages) :

- Acc√®s : [https://martinezcoralie.github.io/dbt-weather-poc/](https://martinezcoralie.github.io/dbt-weather-poc/)

üëâ Documentation d√©taill√©e : [`docs/dbt-docs.md`](docs/dbt-docs.md).

---

## üìä Dashboard Streamlit (exposure dbt)

Lancer le dashboard :

```bash
streamlit run apps/bi-streamlit/app.py
```

Acc√®s : [http://localhost:8501](http://localhost:8501)

Le dashboard consomme les marts dbt stock√©s dans DuckDB (dimensions de stations, √©chelle de Beaufort, faits horaires).

üëâ D√©tails : [`docs/dashboard.md`](docs/dashboard.md).

---


## ‚úÖ CI dbt (build + API M√©t√©o-France)

Une CI GitHub Actions rejoue une partie du pipeline √† chaque push / PR sur `main` :

- ingestion des donn√©es brutes depuis l‚ÄôAPI M√©t√©o-France via `make dwh-ingest DEPT=9`,
- cr√©ation d‚Äôun warehouse DuckDB local dans l‚Äôenvironnement CI,
- ex√©cution de `dbt deps` puis `dbt build` avec `DBT_PROFILES_DIR=./profiles`.

La CI s‚Äôappuie sur :

- un secret GitHub Actions `METEOFRANCE_TOKEN` (cl√© API M√©t√©o-France),
- une variable d‚Äôenvironnement `DUCKDB_PATH` pointant vers `data/warehouse.duckdb`.

Ce choix permet de tester les mod√®les dbt et leurs tests m√©tier sur des donn√©es r√©elles, sans versionner les donn√©es M√©t√©o-France dans le d√©p√¥t.

---


## ‚öôÔ∏è Orchestration locale (Prefect ‚Äî bonus)

Une orchestration locale est mise en place avec **Prefect 3** :

* un flow `weather_hourly_pipeline` orchestre :

  * l‚Äôingestion (API ‚Üí DuckDB),
  * puis `dbt build`,
* un deployment Prefect avec schedule horaire pilote l‚Äôex√©cution r√©guli√®re du pipeline tant que le serveur Prefect et le process de service tournent.

Cette orchestration est volontairement l√©g√®re : elle sert √† montrer comment **plugger un orchestrateur moderne autour d‚Äôun projet dbt existant**, sans complexifier le c≈ìur du repo.

üëâ D√©tails : [`docs/orchestration.md`](docs/orchestration.md).

---

## üß∞ Commandes (Makefile)

Toutes les commandes (ingestion, dbt, docs, utilitaires DuckDB, lint, etc.) sont centralis√©es dans le **Makefile** :

```bash
make help
```

---

## Scope & limites

Ce projet :

* est centr√© sur la **d√©monstration de bonnes pratiques dbt** (structure, tests, contrats, docs, exposures),
* embarque une CI et une orchestration locale pour illustrer l‚Äôint√©gration de dbt dans un pipeline complet,
* **ne vise pas** (dans cette version) :

  * un d√©ploiement 24/7 sur une infra cloud,
  * une BI m√©tier aboutie.

---

## Prochaines √©volutions

* √âtendre la CI/CD (artefacts, checks suppl√©mentaires, √©ventuels d√©ploiements),
* D√©ployer pipeline + dashboard sur une infra cloud (VM / containers),
* Approfondir l‚Äôorchestration (Prefect Cloud / autre orchestrateur) si besoin projet.

---

## üë§ Auteur

Coralie Martinez
